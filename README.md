# 편의점 행사 상품 크롤러

## 프로젝트 소개

네이버 검색의 '편의점 행사' 페이지를 기반으로 주요 편의점(CU, GS25, 세븐일레븐, 이마트24)의 행사 상품 정보를 수집하고, 그 결과를 JSON 파일과 Supabase 데이터베이스에 저장 및 업데이트하는 자동화 프로젝트입니다.

##  주요 기능

- **통합 크롤러**: 단일 크롤러(`all_crawler.py`)를 통해 여러 편의점의 행사 정보를 한 번에 수집합니다.
- **카테고리별 수집**: '음료', '과자' 등 주요 카테고리별로 상품을 수집하여 데이터에 `category` 정보를 포함합니다.
- **상세 정보 수집**: 상품의 브랜드, 이름, 할인가, 원가, 이미지 URL, 행사 종류(1+1 등)를 상세히 수집합니다.
- **데이터베이스 연동**: 수집된 데이터를 Supabase 데이터베이스의 `products` 테이블에 자동으로 업로드합니다.
- **자동화**: GitHub Actions를 통해 매월 1일 자동으로 크롤러를 실행하며, 필요시 수동 실행도 가능합니다.

##  설치 및 설정

1.  **저장소 복제:**
    ```bash
    git clone [Your-Repository-URL]
    cd [repository-name]
    ```

2.  **가상 환경 생성 및 활성화 (권장):**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```

3.  **필수 라이브러리 설치:**
    > **참고:** `pyroaring` 라이브러리 설치 시 C++ 빌드 도구가 필요할 수 있습니다. 오류가 발생했다면, 먼저 [Microsoft C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)를 설치한 후 아래 명령어를 다시 실행해주세요.
    ```bash
    pip install -r requirements.txt
    ```

4.  **환경 변수 설정 (`.env`):**
    -   프로젝트 루트의 `.env.example` 파일을 복사하여 `.env` 파일을 생성합니다.
    -   `.env` 파일 안에 본인의 Supabase Project URL과 **`service_role` Secret Key**를 입력합니다.
    ```env
    SUPABASE_URL="YOUR_SUPABASE_URL"
    SUPABASE_KEY="YOUR_SUPABASE_KEY"
    ```

5.  **Supabase 테이블 생성:**
    -   Supabase 프로젝트에 아래와 같은 스키마의 `products` 테이블을 생성해야 합니다.
    ```sql
    create table products (
      id bigint generated by default as identity primary key,
      brand text,
      category text,
      name text not null,
      sale_price integer,
      original_price integer,
      image_url text,
      event_type text,
      created_at timestamp with time zone default timezone('utc'::text, now()) not null
    );
    ```

##  사용법

프로젝트 루트 디렉토리에서 다음 명령어를 실행하면 모든 크롤링 및 데이터베이스 업로드 과정이 시작됩니다.

```bash
python main.py
```

##  자동화 (GitHub Actions)

-   이 프로젝트는 `.github/workflows/main.yml`에 정의된 워크플로우를 통해 자동화됩니다.
-   **실행 주기**: 매월 1일 자동으로 실행됩니다.
-   **수동 실행**: GitHub 저장소의 'Actions' 탭에서 'Monthly Product Crawl' 워크플로우를 선택하여 언제든지 수동으로 실행할 수 있습니다.
-   **주의**: 자동화를 위해서는 GitHub 저장소의 `Settings > Secrets and variables > Actions`에 `SUPABASE_URL`과 `SUPABASE_KEY`가 반드시 등록되어 있어야 합니다.
